{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow\n",
    "import math\n",
    "import pywt\n",
    "import keras\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import shutil\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hough Transform\n",
    "# Returns (image, radius, success<true>) / (image, image.shape[0], success<false>)\n",
    "\n",
    "\n",
    "def process_hough(imagepath, image, radius):\n",
    "\n",
    "    image = cv2.resize(image, (640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = cv2.medianBlur(image, 11)\n",
    "\n",
    "    edge = cv2.Canny(image, 100, 200)\n",
    "\n",
    "    ret, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1,\n",
    "\n",
    "\n",
    "\n",
    "                               50, param1=ret, param2=30, minRadius=20, maxRadius=100)\n",
    "\n",
    "\n",
    "    try:\n",
    "        circles = circles[0, :, :]\n",
    "\n",
    "        circles = np.int16(np.array(circles))\n",
    "\n",
    "        success = False\n",
    "\n",
    "\n",
    "        for i in circles[:]:\n",
    "\n",
    "            image = image[\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                i[1] - i[2] - radius: i[1] + i[2] + radius,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                i[0] - i[2] - radius: i[0] + i[2] + radius\n",
    "                # i[1] - i[2] : i[1] + i[2], i[0] - i[2] : i[0] + i[2]\n",
    "            ]\n",
    "\n",
    "\n",
    "            radius = i[2]\n",
    "\n",
    "        success = True\n",
    "\n",
    "        return (image, radius, success)\n",
    "\n",
    "\n",
    "    except:\n",
    "\n",
    "        image[:] = 255\n",
    "\n",
    "\n",
    "        print(f\"{imagepath} -> No circles (iris) found.\")\n",
    "        success = False\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        # Wait for a key press (blocks execution)\n",
    "        # cv2.waitKey(0)\n",
    "        return (image, image.shape[0], success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Images\n",
    "def remove_reflection(image):  # returns image\n",
    "    ret, mask = cv2.threshold(\n",
    "        image, 150, 255, cv2.THRESH_BINARY\n",
    "    )\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "    image_rr = cv2.inpaint(\n",
    "        image, dilation, 5, cv2.INPAINT_TELEA\n",
    "    )\n",
    "\n",
    "    return image_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daugman Rubber Sheet Model\n",
    "def generate_rubber_sheet_model(image):  # returns image\n",
    "    q = np.arange(0.00, np.pi * 2, 0.01)\n",
    "    inn = np.arange(0, int(image.shape[0] / 2), 1)\n",
    "\n",
    "    cartisian_image = np.empty(shape=[inn.size, int(image.shape[1]), 3])\n",
    "    m = interp1d([np.pi * 2, 0], [0, image.shape[1]])\n",
    "\n",
    "    for r in inn:\n",
    "        for t in q:\n",
    "            polarX = int((r * np.cos(t)) + image.shape[1] / 2)\n",
    "            polarY = int((r * np.sin(t)) + image.shape[0] / 2)\n",
    "            try:\n",
    "                cartisian_image[r][int(m(t) - 1)] = image[polarY][polarX]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # for image in cartisian_image:\n",
    "    #     print(image.size)\n",
    "    # print(cartisian_image.size)\n",
    "    # cartisian_image = (filter(lambda image: print((image.size)), cartisian_image))\n",
    "\n",
    "    return cartisian_image.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Iris Dataset\n",
    "# Returns images(image, image_id, label)\n",
    "def parse_iris_dataset(keep_reflections):\n",
    "    # eye_num_2 = 0\n",
    "    # final_output = []\n",
    "    # lables = []\n",
    "    label = 0\n",
    "    eye_images = []\n",
    "    eye_L_images = []\n",
    "    eye_R_images = []\n",
    "\n",
    "    base_directory = 'Dataset/VISA_Iris/VISA_Iris'\n",
    "\n",
    "    for path in glob.iglob(base_directory+'/*'):\n",
    "        foldername = os.path.basename(path)\n",
    "        label = foldername\n",
    "        print('label: ' + label)\n",
    "        image_id = 1\n",
    "\n",
    "        # Process Left Eye\n",
    "        for image_path in glob.iglob(path+'/L/*'):\n",
    "            eye = '-left'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            image_hough_processed = process_hough(\n",
    "                image_path, image, 50)  # hough transform\n",
    "\n",
    "            if (keep_reflections):\n",
    "                image = remove_reflection(image)\n",
    "\n",
    "            (testimage, x, success) = image_hough_processed\n",
    "            if (success):\n",
    "                # just left iris\n",
    "                eye_L_images.append([image_hough_processed, image_id, label])\n",
    "                eye_images.append([image_hough_processed, image_id, label])\n",
    "                image_id += 1\n",
    "            else:\n",
    "                pass\n",
    "        print('L eye: ' + str(len(eye_L_images)))\n",
    "\n",
    "        image_id = 1\n",
    "        # Process Right Eye\n",
    "        for image_path in glob.iglob(path+'/R/*'):\n",
    "            eye = '-right'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            image_hough_processed = process_hough(\n",
    "                image_path, image, 50)  # hough transform\n",
    "\n",
    "            if (keep_reflections):\n",
    "                remove_reflection(image_hough_processed)\n",
    "\n",
    "            # image = cv2.resize(image, (400, 300))\n",
    "            (testimage, x, success) = image_hough_processed\n",
    "            if (success):\n",
    "                eye_R_images.append([image_hough_processed, image_id, label])\n",
    "                eye_images.append([image_hough_processed, image_id, label+eye])\n",
    "                image_id += 1\n",
    "            else:\n",
    "                pass\n",
    "        print('R iris: ' + str(len(eye_R_images)))\n",
    "\n",
    "        # old code insert here\n",
    "    print('iris images: ' + str(len(eye_images)))\n",
    "\n",
    "    return eye_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proccess to Daugman\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def process_images(eye_images):\n",
    "    for eye_image in eye_images:\n",
    "        (hough_information, image_id, label) = eye_image\n",
    "        (image, radius, success) = hough_information\n",
    "        print(str(image_id) + ': ' + str(success))\n",
    "        if (success == True and image.size > 0):\n",
    "            image_daugman = generate_rubber_sheet_model(image)\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "            # cv2.waitKey(0)\n",
    "        print(\"id\" + str(image_id))\n",
    "        print((image_daugman))\n",
    "        cv2.imwrite(\n",
    "            f'Iris_Output/{str(label)}.{str(image_id)}.Iris.bmp',\n",
    "            image_daugman\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_reflections = False\n",
    "eye_images = parse_iris_dataset(keep_reflections)\n",
    "# for eye in eye_images:\n",
    "#    image, image_id, label = eye\n",
    "#    cv2.imshow(str(label)+': ' + str(image_id) + '', image)\n",
    "#     cv2.waitKey(0)\n",
    "stuff = process_images(eye_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSOLETE - Detect Iris using Iris Cascade\n",
    "def detect_iris(eye_images, display):\n",
    "    eye_num_2 = 0\n",
    "    eyes_num = 0\n",
    "    # explain how this works in presentation\n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_iris.xml')\n",
    "    for eye_image in eye_images:\n",
    "        (image, image_id, label) = eye_image\n",
    "        image_id += 1\n",
    "        eyes = eye_cascade.detectMultiScale(image, 1.1, 0)\n",
    "\n",
    "        if len(eyes) > 1:  # idk what is happening\n",
    "            eyes_num = eyes_num + 1\n",
    "            maxium_area = -3\n",
    "\n",
    "        for (x, y, width, height) in eyes:\n",
    "            area = width * height\n",
    "\n",
    "            if area > maxium_area:\n",
    "                maxium_area = area\n",
    "                maxium_width = width\n",
    "                point_x = x\n",
    "                point_y = y\n",
    "                maxium_height = height\n",
    "\n",
    "        image_unboxed = image.copy()\n",
    "\n",
    "        image_cropped = image_unboxed[point_y:point_y + maxium_height,\n",
    "                                      point_x:point_x + maxium_width,]\n",
    "\n",
    "        image_boxed = cv2.rectangle(\n",
    "            image,\n",
    "            (point_x, point_y),\n",
    "            (point_x + maxium_width, point_y + maxium_height),\n",
    "            (255, 0, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(\n",
    "            'Processed/'+str(label) + '.' + str(image_id) + '.Iris' + '.bmp',\n",
    "            image_cropped\n",
    "        )\n",
    "\n",
    "    print(\"iris image preprocessing done\")\n",
    "\n",
    "    if (display):\n",
    "        fig, axes = plot.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "        axes[0].imshow(image_unboxed)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')  # Hide axes for cleaner presentation\n",
    "\n",
    "        axes[1].imshow(image_boxed)\n",
    "        axes[1].set_title('Iris Detection')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        axes[2].imshow(image_cropped)\n",
    "        axes[2].set_title('Cropped Image')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        plot.tight_layout()\n",
    "        plot.show()\n",
    "\n",
    "    print(\"total_eyes_found = \", eyes_num)\n",
    "    print(\"total_eyes_found 2 = \", eye_num_2)\n",
    "    print(\"total images: \", len(eye_images))\n",
    "\n",
    "\n",
    "eye_images = parse_iris_dataset()\n",
    "detect_iris(eye_images, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def processing(image_path, r):\n",
    "    success = False\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(image, 11)\n",
    "    ret, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        1,\n",
    "        50,\n",
    "        param1=ret,\n",
    "        param2=30,\n",
    "        minRadius=20,\n",
    "        maxRadius=100,\n",
    "    )\n",
    "    try:\n",
    "        circles = circles[0, :, :]\n",
    "        circles = np.int16(np.array(circles))\n",
    "        for i in circles[:]:\n",
    "            image = image[\n",
    "                i[1] - i[2] - r: i[1] + i[2] + r, i[0] - i[2] - r: i[0] + i[2] + r\n",
    "                # i[1] - i[2] : i[1] + i[2], i[0] - i[2] : i[0] + i[2]\n",
    "            ]\n",
    "            radius = i[2]\n",
    "        success = True\n",
    "        return image, radius, success\n",
    "    except:\n",
    "        image[:] = 255\n",
    "        print(f\"{image_path} -> No circles (iris) found.\")\n",
    "        success = False\n",
    "        return image, image.shape[0], success\n",
    "\n",
    "\n",
    "def generate_rubber_sheet_model(img):\n",
    "    q = np.arange(0.00, np.pi * 2, 0.01)\n",
    "    inn = np.arange(0, int(img.shape[0] / 2), 1)\n",
    "\n",
    "    cartisian_image = np.empty(shape=[inn.size, int(img.shape[1]), 3])\n",
    "    m = interp1d([np.pi * 2, 0], [0, img.shape[1]])\n",
    "\n",
    "    for r in inn:\n",
    "        for t in q:\n",
    "            polarX = int((r * np.cos(t)) + img.shape[1] / 2)\n",
    "            polarY = int((r * np.sin(t)) + img.shape[0] / 2)\n",
    "            try:\n",
    "                cartisian_image[r][int(m(t) - 1)] = img[polarY][polarX]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return cartisian_image.astype(\"uint8\")\n",
    "\n",
    "\n",
    "def remove_reflection(img):\n",
    "    ret, mask = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "    dst = cv2.inpaint(img, dilation, 5, cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def feature_extraction(img):\n",
    "    features = []\n",
    "    ccoeffs = pywt.dwt2(img[:, :, 0], 'haar')\n",
    "    LL, (LH, HL, HH) = ccoeffs\n",
    "    for coef in [LL, LH, HL, HH]:\n",
    "        features.append(np.mean(coef))\n",
    "        features.append(np.std(coef))\n",
    "        features.append(np.max(coef))\n",
    "        features.append(np.min(coef))\n",
    "        features.append(np.median(coef))\n",
    "\n",
    "    titles = ['Approximation (LL)', 'Horizontal Detail (LH)',\n",
    "              'Vertical Detail (HL)', 'Diagonal Detail (HH)']\n",
    "    images = [LL, LH, HL, HH]\n",
    "    # Plot all DWT coefficients horizontally in a single graph\n",
    "    plt.figure(figsize=(12, 4))  # Adjust the figure size as needed\n",
    "\n",
    "    for i, (title, image) in enumerate(zip(titles, images), 1):\n",
    "        plt.subplot(1, 4, i)  # Arrange subplots in a single row\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return features\n",
    "\n",
    "# Display the original and DWT coefficients\n",
    "\n",
    "\n",
    "imagepath = \"Dataset/VISA_Iris/VISA_Iris/S0001_F_30/R/1.bmp\"\n",
    "\n",
    "# hough\n",
    "hough_information = processing(imagepath, 60)\n",
    "(image1, radius, success) = hough_information\n",
    "\n",
    "# remove reflection\n",
    "imageN = remove_reflection(image1)\n",
    "\n",
    "# daugman\n",
    "sheet = generate_rubber_sheet_model(image1)\n",
    "sheetN = generate_rubber_sheet_model(imageN)\n",
    "\n",
    "# dwt reflection\n",
    "dwt_feature = feature_extraction(sheet)\n",
    "\n",
    "# dwt no reflection\n",
    "dwt_featureN = feature_extraction(sheetN)\n",
    "\n",
    "print(\"DWT Features:\", dwt_feature)\n",
    "print(\"DWT Features N:\", dwt_featureN)\n",
    "\n",
    "fig, axes = plot.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(imageN)\n",
    "axes[0].set_title('Iris Image')\n",
    "axes[0].axis('off')  # Hide axes for cleaner presentation\n",
    "\n",
    "axes[1].imshow(sheetN)\n",
    "axes[1].set_title('Daugman Rubber Sheet')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# axes[2].imshow()\n",
    "# axes[2].set_title('Daugman Rubber Sheet')\n",
    "# axes[2].axis('off')\n",
    "\n",
    "plot.tight_layout()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "imagepath = \"Dataset/VISA_Iris/VISA_Iris/S0001_F_30/L/2.bmp\"\n",
    "# original_eye = cv2.imread(imagepath)\n",
    "# cv2.imshow(\"frame1\", original_eye)\n",
    "eye_image = cv2.imread(imagepath, cv2.IMREAD_GRAYSCALE)\n",
    "# cv2.imshow(\"frame2\", eye_image)\n",
    "\n",
    "\n",
    "eye_circles = cv2.HoughCircles(\n",
    "    eye_image, cv2.HOUGH_GRADIENT, 2, 100,  minRadius=90, maxRadius=200)\n",
    "\n",
    "if eye_circles is not None:\n",
    "    circle = eye_circles[0][0]\n",
    "    iris_coordinates = (circle[0], circle[1])\n",
    "\n",
    "if iris_coordinates is not None:\n",
    "    x = int(iris_coordinates[0])\n",
    "    y = int(iris_coordinates[1])\n",
    "\n",
    "    w = int(round(circle[2]) + 10)\n",
    "    h = int(round(circle[2]) + 10)\n",
    "\n",
    "    # cv2.circle(original_eye, iris_coordinates, int(circle[2]), (255,0,0), thickness=2)\n",
    "    image_hough_processed = eye_image[y-h:y+h, x-w:x+w]\n",
    "    iris_image_to_show = cv2.resize(\n",
    "        image_hough_processed, (image_hough_processed.shape[1]*2, image_hough_processed.shape[0]*2))\n",
    "\n",
    "q = np.arange(0.00, np.pi*2, 0.01)  # theta\n",
    "inn = np.arange(0, int(iris_image_to_show.shape[0]/2), 1)  # radius\n",
    "\n",
    "cartisian_image = np.empty(\n",
    "    shape=[inn.size, int(iris_image_to_show.shape[1]), 3])\n",
    "m = interp1d([np.pi*2, 0], [0, iris_image_to_show.shape[1]])\n",
    "\n",
    "for r in inn:\n",
    "    for t in q:\n",
    "        polarX = int((r * np.cos(t)) + iris_image_to_show.shape[1]/2)\n",
    "        polarY = int((r * np.sin(t)) + iris_image_to_show.shape[0]/2)\n",
    "        cartisian_image[r][int(m(t) - 1)] = iris_image_to_show[polarY][polarX]\n",
    "\n",
    "iris_image_to_show\n",
    "# im.save('eye.jpeg')\n",
    "cartisian_image = cartisian_image.astype('uint8')\n",
    "# im.save('cartesian_eye.jpeg')\n",
    "\n",
    "fig, axes = plot.subplots(1, 3, figsize=(12, 5))\n",
    "axes[0].imshow(eye_image)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')  # Hide axes for cleaner presentation\n",
    "\n",
    "axes[1].imshow(iris_image_to_show)\n",
    "axes[1].set_title('Haar Iris Cascade Classifier Detection')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cartisian_image)\n",
    "axes[2].set_title('Cropped Eye')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plot.tight_layout()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_iris_dataset():\n",
    "    eye_num_2 = 0\n",
    "    label = 0\n",
    "    eye_images = []\n",
    "    eye_L_images = []\n",
    "    eye_R_images = []\n",
    "    final_output = []\n",
    "    lables = []\n",
    "\n",
    "    base_directory = 'Dataset/VISA_Iris/VISA_Iris'\n",
    "\n",
    "    for path in glob.iglob(base_directory+'/*'):\n",
    "        foldername = os.path.basename(path)\n",
    "        label = foldername\n",
    "        print('label: ' + label)\n",
    "        image_id = 0\n",
    "\n",
    "        for image_path in glob.iglob(path+'/L/*'):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (400, 300))\n",
    "            eye_L_images.append([image, image_id, label])  # just left iris\n",
    "            eye_images.append([image, image_id, label])\n",
    "            image_id += 1\n",
    "        print('L eye: ' + str(len(eye_L_images)))\n",
    "\n",
    "        for image_path in glob.iglob(path+'/R/*'):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (400, 300))\n",
    "            eye_R_images.append([image, image_id, label])  # just right iris\n",
    "            eye_images.append([image, image_id, label])\n",
    "            image_id += 1\n",
    "        print('R iris: ' + str(len(eye_R_images)))\n",
    "\n",
    "    print('iris images: ' + str(len(eye_images)))\n",
    "    return eye_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_detection(eye_images, display):\n",
    "    eye_num_2 = 0\n",
    "    eyes_num = 0\n",
    "    # explain how this works in presentation\n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    for eye_image in eye_images:\n",
    "        (image, image_id, label) = eye_image\n",
    "        image_id += 1\n",
    "        eyes = eye_cascade.detectMultiScale(image, 1.1, 0)\n",
    "\n",
    "        if len(eyes) > 1:  # idk what is happening\n",
    "            eyes_num = eyes_num + 1\n",
    "            maxium_area = -3\n",
    "\n",
    "        for (x, y, width, height) in eyes:\n",
    "            area = width * height\n",
    "\n",
    "            if area > maxium_area:\n",
    "                maxium_area = area\n",
    "                maxium_width = width\n",
    "                point_x = x\n",
    "                point_y = y\n",
    "                maxium_height = height\n",
    "        # test\n",
    "            # pupil_frame = image[y:y + height, x:x + width]\n",
    "            # ret, thresh = cv2.threshold(pupil_frame, 80, 255, cv2.THRESH_BINARY)\n",
    "            # cv2.imshow(\"threshold\", thresh)\n",
    "            # im2, contours = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # print(contours)\n",
    "        # endtest\n",
    "\n",
    "        # test\n",
    "            # for contour in contours:\n",
    "            #     area = cv2.contourArea(contour)\n",
    "            #     rect = cv2.boundingRect(contour)\n",
    "            #     x, y, w, h = rect\n",
    "            #     radius = 0.15 * (w + h)\n",
    "\n",
    "            #     area_condition = (100 <= area <= 200)\n",
    "            #     symmetry_condition = (abs(1 - float(w)/float(h)) <= 0.2)\n",
    "            #     fill_condition = (abs(1 - (area / (math.pi * math.pow(radius, 2.0)))) <= 0.4)\n",
    "            #     cv2.circle(image, (int(x + x + radius), int(y + y + radius)), int(1.3 * radius), (0, 180, 0), -1)\n",
    "\n",
    "            # cv2.imshow('Pupil Detector', image)\n",
    "            # c = cv2.waitKey(1)\n",
    "            # if c == 27:\n",
    "            #     break\n",
    "        # #endtest\n",
    "\n",
    "        image_unboxed = image.copy()\n",
    "\n",
    "        image_cropped = image_unboxed[point_y:point_y + maxium_height,\n",
    "                                      point_x:point_x + maxium_width,]\n",
    "\n",
    "        image_boxed = cv2.rectangle(\n",
    "            image,\n",
    "            (point_x, point_y),\n",
    "            (point_x+maxium_width, maxium_height),\n",
    "            (255, 0, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(\n",
    "            'Processed/'+str(label) + '.' + str(image_id) + '.Iris' + '.bmp',\n",
    "            image_cropped\n",
    "        )\n",
    "    if (display):\n",
    "        fig, axes = plot.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "        axes[0].imshow(image_unboxed)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')  # Hide axes for cleaner presentation\n",
    "\n",
    "        axes[1].imshow(image_boxed)\n",
    "        axes[1].set_title('Haar Iris Cascade Classifier Detection')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        axes[2].imshow(image_cropped)\n",
    "        axes[2].set_title('Cropped Eye')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        plot.tight_layout()\n",
    "        plot.show()\n",
    "\n",
    "    print(\"total_eyes_found = \", eyes_num)\n",
    "    print(\"total_eyes_found 2 = \", eye_num_2)\n",
    "    print(\"total images: \", len(eye_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_images = parse_iris_dataset()\n",
    "# param 2 is for display (1 = display, 0 = don't display)\n",
    "iris_detection(eye_images, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
