{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parsing Face Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'Dataset/VISA_Face/VISA_Face'\n",
    "face_images = []\n",
    "\n",
    "\n",
    "def parse_face_dataset():\n",
    "    # Clear the face_images list before processing the dataset\n",
    "    face_images.clear()\n",
    "\n",
    "    for path in glob.iglob(base_directory + '/*'):\n",
    "        filename = os.path.basename(path)\n",
    "\n",
    "        # string manipulation\n",
    "        underscore_index = filename.find(\"_\")\n",
    "        filename_parsed = filename[:underscore_index]\n",
    "        match = re.search(r\"(.*?)_2017_001\", filename)\n",
    "        if match:\n",
    "            filename_parsed = match.group(1)\n",
    "        else:\n",
    "            warnings.warn(f\"No match found for filename: {filename}\")\n",
    "            continue  # Skip processing this file\n",
    "\n",
    "        label = filename_parsed\n",
    "        image_id = 0\n",
    "\n",
    "        for image_path in glob.iglob(path + '/*'):\n",
    "            try:\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if image is None:\n",
    "                    warnings.warn(f\"Failed to load image: {image_path}\")\n",
    "                    continue\n",
    "                # Resize image to reduce memory usage\n",
    "                image = cv2.resize(image, (400, 300))\n",
    "                face_images.append([image, image_id, label])\n",
    "                image_id += 1\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"Error processing image: {image_path}\\n{e}\")\n",
    "\n",
    "    print('Total Face Images Found: ' + str(len(face_images)))\n",
    "\n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Face Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def face_detection(face_images, display):\n",
    "    pre_processed_images = []\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "    # Output directory for storing the detected faces\n",
    "    output_dir = os.path.join('Face_Output', 'Face_Output_Detection')\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    if os.path.exists(output_dir):\n",
    "        for filename in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for face_image in face_images:\n",
    "        (image, image_id, label) = face_image\n",
    "        image_id += 1\n",
    "        faces = face_cascade.detectMultiScale(image, 1.1, 4)\n",
    "\n",
    "        for (x, y, width, height) in faces:\n",
    "            face = image[y:y + height, x:x + width]\n",
    "\n",
    "            # Save cropped face image\n",
    "            output_path = os.path.join(\n",
    "                output_dir, f'{label}_{image_id}_Cropped.jpg')\n",
    "            cv2.imwrite(output_path, face)\n",
    "\n",
    "            pre_processed_images.append([face, image_id, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Face Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_feature_extraction(input_directory, output_dir):\n",
    "    # Initialize face detector and shape predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor_path = 'Dependencies/shape_predictor_68_face_landmarks.dat'\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, 'Face_Output_Feature_Extraction')\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)  # Remove the directory and its contents\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize lists to store features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over images in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(input_directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Detect faces in the image\n",
    "            dets = detector(image, 1)\n",
    "\n",
    "            # Iterate over detected faces\n",
    "            for i, d in enumerate(dets):\n",
    "                # Predict facial landmarks\n",
    "                shape = predictor(image, d)\n",
    "\n",
    "                # Extract features\n",
    "                # Distance between the eyes\n",
    "                eye_distance = shape.part(45).x - shape.part(36).x\n",
    "                nose_shape = calculate_nose_shape(shape)  # Shape of the nose\n",
    "                lips_contour = calculate_lips_contour(\n",
    "                    shape)  # Contour of the lips\n",
    "                # Patterns of wrinkles around the mouth\n",
    "                mouth_wrinkles = calculate_mouth_wrinkles(shape)\n",
    "\n",
    "                # Append features to the feature vector\n",
    "                feature_vector = [eye_distance] + \\\n",
    "                    nose_shape + lips_contour + mouth_wrinkles\n",
    "\n",
    "                # Add feature vector and filename as label\n",
    "                features.append(feature_vector)\n",
    "                labels.append(filename)\n",
    "\n",
    "                # Draw lines between facial landmarks on the image\n",
    "                draw_lines(image, shape)\n",
    "\n",
    "            # Save image with landmarks and detected faces\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def calculate_eye_distance(shape):\n",
    "    # Calculate the Euclidean distance between the outer corners of the eyes\n",
    "    left_eye_outer_corner = (shape.part(36).x, shape.part(36).y)\n",
    "    right_eye_outer_corner = (shape.part(45).x, shape.part(45).y)\n",
    "    eye_distance = math.sqrt((right_eye_outer_corner[0] - left_eye_outer_corner[0])**2 + (\n",
    "        right_eye_outer_corner[1] - left_eye_outer_corner[1])**2)\n",
    "    return eye_distance\n",
    "\n",
    "\n",
    "def calculate_nose_shape(shape):\n",
    "    # Calculate the shape of the nose based on the landmarks\n",
    "    # This is just an example, you may need to define your own logic\n",
    "    # Return a list of values representing the nose shape\n",
    "    nose_shape = []\n",
    "    # Example: Append the x and y coordinates of some nose landmarks\n",
    "    nose_shape.append(shape.part(30).x)  # Tip of the nose\n",
    "    nose_shape.append(shape.part(33).y)  # Bridge of the nose\n",
    "    return nose_shape\n",
    "\n",
    "\n",
    "def calculate_lips_contour(shape):\n",
    "    # Calculate the contour of the lips based on the landmarks\n",
    "    # This is just an example, you may need to define your own logic\n",
    "    # Return a list of values representing the lips contour\n",
    "    lips_contour = []\n",
    "    # Example: Append the x and y coordinates of some lip landmarks\n",
    "    lips_contour.append(shape.part(48).x)  # Left corner of the lips\n",
    "    lips_contour.append(shape.part(54).x)  # Right corner of the lips\n",
    "    return lips_contour\n",
    "\n",
    "\n",
    "def calculate_mouth_wrinkles(shape):\n",
    "    # Calculate the patterns of wrinkles around the mouth based on the landmarks\n",
    "    # This is just an example, you may need to define your own logic\n",
    "    # Return a list of values representing the mouth wrinkles\n",
    "    mouth_wrinkles = []\n",
    "    # Example: Calculate the difference in y-coordinates between upper and lower lip\n",
    "    upper_lip_y = shape.part(51).y\n",
    "    lower_lip_y = shape.part(57).y\n",
    "    mouth_wrinkles.append(lower_lip_y - upper_lip_y)\n",
    "    return mouth_wrinkles\n",
    "\n",
    "\n",
    "def draw_lines(image, shape):\n",
    "    # Draw lines between specific facial landmarks\n",
    "    lines = [(30, 33), (48, 54), (48, 57), (36, 45)]  # Nose, lips, eyes\n",
    "    for start, end in lines:\n",
    "        cv2.line(image, (shape.part(start).x, shape.part(start).y),\n",
    "                 (shape.part(end).x, shape.part(end).y), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Face Landmarks Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facial_landmarks(input_dir, output_dir):\n",
    "    # Initialize face detector and shape predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\n",
    "        'Dependencies/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, 'Face_Output_Landmark_Extraction')\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)  # Remove the directory and its contents\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over images in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Detect faces in the image\n",
    "            dets = detector(image, 1)\n",
    "\n",
    "            # Iterate over detected faces\n",
    "            for i, d in enumerate(dets):\n",
    "                shape = predictor(image, d)\n",
    "                landmarks = [(shape.part(i).x, shape.part(i).y)\n",
    "                             for i in range(68)]\n",
    "\n",
    "                # Draw landmarks on the image\n",
    "                for (x, y) in landmarks:\n",
    "                    cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "                # Save the image with landmarks\n",
    "                output_path = os.path.join(\n",
    "                    output_dir, f'{os.path.splitext(filename)[0]}_landmarks_{i}.jpg')\n",
    "                cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Landmarks to Feature Conversion Vectors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_to_features(landmarks, output_dir):\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, 'Face_Output_LFCV')\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)  # Remove the directory and its contents\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i, landmark_set in enumerate(landmarks):\n",
    "        feature_vector = np.array(landmark_set).flatten()\n",
    "        output_path = os.path.join(output_dir, f'landmarks_{i}.npy')\n",
    "        np.save(output_path, feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saish\\AppData\\Local\\Temp\\ipykernel_1708\\3358766179.py:19: UserWarning: No match found for filename: olivetti_py3.pkz\n",
      "  warnings.warn(f\"No match found for filename: {filename}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Face Images Found: 558\n",
      "Parsing Face Dataset STARTED...\n",
      "Parsing Face Dataset COMPLETE!\n",
      "Face Image Preprocessing STARTED...\n",
      "Face Image Preprocessing COMPLETE!\n",
      "Face Feature Extraction STARTED...\n",
      "Face Feature Extraction COMPLETE!\n",
      "Extracting facial landmarks STARTED...\n",
      "Extracting facial landmarks COMPLETE!\n",
      "Converting facial landmarks to feature vectors STARTED...\n",
      "Converting facial landmarks to feature vectors COMPLETE!\n",
      "Number of feature vectors generated: 328\n",
      "Training set size: 262\n",
      "Testing set size: 66\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # PHASE 1 - Parse the face dataset\n",
    "    face_images = parse_face_dataset()\n",
    "    print(\"Parsing Face Dataset STARTED...\")\n",
    "    print(\"Parsing Face Dataset COMPLETE!\")\n",
    "\n",
    "# PHASE 2 - Perform face detection\n",
    "    print(\"Face Image Preprocessing STARTED...\")\n",
    "    # Suppress display for face detection\n",
    "    face_detection(face_images, display=False)\n",
    "    print(\"Face Image Preprocessing COMPLETE!\")\n",
    "\n",
    "# PHASE 3 - Perform facial feature extraction\n",
    "    print(\"Face Feature Extraction STARTED...\")\n",
    "    # Input directory containing images with detected faces\n",
    "    input_directory = 'Face_Output/Face_Output_Detection'\n",
    "\n",
    "    # Output directory for saving images with landmarks and detected faces\n",
    "    output_directory = 'Face_Output'\n",
    "\n",
    "    features, labels = facial_feature_extraction(\n",
    "        input_directory, output_directory)\n",
    "    print(\"Face Feature Extraction COMPLETE!\")\n",
    "\n",
    "# PHASE 4 - Extract facial landmarks from an image\n",
    "    print(\"Extracting facial landmarks STARTED...\")\n",
    "    # Input directory containing images with extracted facial features\n",
    "    input_directory = 'Face_Output/Face_Output_Feature_Extraction'\n",
    "\n",
    "    # Output directory for saving images with facial landmarks\n",
    "    output_directory = 'Face_Output'\n",
    "\n",
    "    extract_facial_landmarks(input_directory, output_directory)\n",
    "    print(\"Extracting facial landmarks COMPLETE!\")\n",
    "\n",
    "# PHASE 5 - Convert facial landmarks into feature vectors\n",
    "    print(\"Converting facial landmarks to feature vectors STARTED...\")\n",
    "    landmarks_to_features(features, output_dir='Face_Output')\n",
    "    print(\"Converting facial landmarks to feature vectors COMPLETE!\")\n",
    "\n",
    "    # Post-Phase 5\n",
    "    print(\"Number of feature vectors generated:\", len(\n",
    "        os.listdir('Face_Output/Face_Output_LFCV')))\n",
    "\n",
    "# PHASE 6 - Splitting Data (80% Training, 20% Test)\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Print the sizes of the training and testing sets\n",
    "    print(\"Training set size:\", len(X_train))\n",
    "    print(\"Testing set size:\", len(X_test))\n",
    "\n",
    " # PHASE 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
