{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re \n",
    "import warnings\n",
    "import dlib\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "faces = fetch_olivetti_faces()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'Dataset/VISA_Face/VISA_Face'\n",
    "face_images = []\n",
    "\n",
    "def parse_face_dataset():\n",
    "    for path in glob.iglob(base_directory + '/*'):\n",
    "        filename = os.path.basename(path)\n",
    "        \n",
    "        # string manipulation\n",
    "        underscore_index = filename.find(\"_\")\n",
    "        filename_parsed = filename[:underscore_index]    \n",
    "        match = re.search(r\"(.*?)_2017_001\", filename)\n",
    "        if match:\n",
    "            filename_parsed = match.group(1)\n",
    "        else:\n",
    "            warnings.warn(f\"No match found for filename: {filename}\")\n",
    "            continue  # Skip processing this file\n",
    "        \n",
    "        label = filename_parsed\n",
    "        image_id = 0\n",
    "        \n",
    "        for image_path in glob.iglob(path + '/*'):\n",
    "            try:\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if image is None:\n",
    "                    warnings.warn(f\"Failed to load image: {image_path}\")\n",
    "                    continue\n",
    "                image = cv2.resize(image, (400, 300))  # Resize image to reduce memory usage\n",
    "                face_images.append([image, image_id, label])\n",
    "                image_id += 1\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"Error processing image: {image_path}\\n{e}\")\n",
    "            \n",
    "    print('Total Face Images Found: ' + str(len(face_images)))   \n",
    "    return face_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def face_detection(face_images, display):\n",
    "    pre_processed_images = []\n",
    "    print(\"Face Image Preprocessing STARTED...\")\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join('Face_Output', 'Face_Output_Detection')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "    for face_image in face_images:\n",
    "        (image, image_id, label) = face_image\n",
    "        image_id += 1\n",
    "        faces = face_cascade.detectMultiScale(image, 1.1, 4)\n",
    "\n",
    "        for (x, y, width, height) in faces:\n",
    "            face = image[y:y + height, x:x + width]\n",
    "\n",
    "            # Save cropped face image\n",
    "            output_path = os.path.join(output_dir, f'{label}_{image_id}_Cropped.jpg')\n",
    "            cv2.imwrite(output_path, face)\n",
    "\n",
    "            pre_processed_images.append([face, image_id, label])\n",
    "\n",
    "    print(\"Face Image Preprocessing COMPLETE...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_feature_extraction(output_dir):\n",
    "    # Initialize face detector and shape predictor\n",
    "    print(\"Face Feature Extraction STARTED...\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor_path = 'Dependencies/shape_predictor_68_face_landmarks.dat'\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, 'Face_Output_Feature_Extraction')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to the directory containing cropped face images\n",
    "    detection_dir = os.path.join('Face_Output', 'Face_Output_Detection')\n",
    "\n",
    "    # Clear output directory if it already exists\n",
    "    for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}: {e}\")\n",
    "    \n",
    "    # Iterate over images in the detection directory\n",
    "    for filename in os.listdir(detection_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(detection_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Detect faces in the image\n",
    "            dets = detector(image, 1)\n",
    "            \n",
    "            # Iterate over detected faces\n",
    "            for i, d in enumerate(dets):\n",
    "                # Predict facial landmarks\n",
    "                shape = predictor(image, d)\n",
    "                \n",
    "                # Draw landmarks on the image\n",
    "                for i in range(68):\n",
    "                    cv2.circle(image, (shape.part(i).x, shape.part(i).y), 1, (0, 255, 0), -1)\n",
    "                    \n",
    "                # Draw rectangle around the face\n",
    "                cv2.rectangle(image, (d.left(), d.top()), (d.right(), d.bottom()), (255, 0, 0), 2)\n",
    "                    \n",
    "            # Save image with landmarks and detected faces\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "    \n",
    "    # Print message when feature extraction is done\n",
    "    print(\"Face Feature Extraction COMPLETE...\")\n",
    "\n",
    "# Example usage\n",
    "output_directory = 'Face_Output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saish\\AppData\\Local\\Temp\\ipykernel_16248\\3743092712.py:15: UserWarning: No match found for filename: olivetti_py3.pkz\n",
      "  warnings.warn(f\"No match found for filename: {filename}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Face Images Found: 558\n",
      "Face Image Preprocessing STARTED...\n",
      "Face Image Preprocessing COMPLETE...\n",
      "Face Feature Extraction STARTED...\n",
      "Face Feature Extraction COMPLETE...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    face_images = parse_face_dataset()\n",
    "    face_detection(face_images, display = False)  # Suppress display for face detection\n",
    "    facial_feature_extraction(output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
