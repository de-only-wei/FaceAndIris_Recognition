{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n",
      "Training complete!\n",
      "Data 1 Predicted Label: S0001_F_30_20_Cropped.jpg Actual Label: S0001_F_30_19_Cropped.jpg\n",
      "Data 2 Predicted Label: S0016_M_34_2_Cropped.jpg Actual Label: S0009_M_22_19_Cropped.jpg\n",
      "Data 3 Predicted Label: S0008_F_25_3_Cropped.jpg Actual Label: S0008_F_25_1_Cropped.jpg\n",
      "Data 4 Predicted Label: S0014_M_54_7_Cropped.jpg Actual Label: S0003_M_32_7_Cropped.jpg\n",
      "Data 5 Predicted Label: S0004_M_16_18_Cropped.jpg Actual Label: S0005_M_11_1_Cropped.jpg\n",
      "Data 6 Predicted Label: S0018_F_43_9_Cropped.jpg Actual Label: S0005_M_11_26_Cropped.jpg\n",
      "Data 7 Predicted Label: S0005_M_11_8_Cropped.jpg Actual Label: S0005_M_11_10_Cropped.jpg\n",
      "Data 8 Predicted Label: S0015_M_26_11_Cropped.jpg Actual Label: S0018_F_43_4_Cropped.jpg\n",
      "Data 9 Predicted Label: S0004_M_16_33_Cropped.jpg Actual Label: S0022_M_47_1_Cropped.jpg\n",
      "Data 10 Predicted Label: S0013_M_34_5_Cropped.jpg Actual Label: S0013_M_34_3_Cropped.jpg\n",
      "Data 11 Predicted Label: S0009_M_22_24_Cropped.jpg Actual Label: S0009_M_22_29_Cropped.jpg\n",
      "Data 12 Predicted Label: S0010_M_24_3_Cropped.jpg Actual Label: S0022_M_47_6_Cropped.jpg\n",
      "Data 13 Predicted Label: S0014_M_54_4_Cropped.jpg Actual Label: S0004_M_16_35_Cropped.jpg\n",
      "Data 14 Predicted Label: S0004_M_16_15_Cropped.jpg Actual Label: S0004_M_16_19_Cropped.jpg\n",
      "Data 15 Predicted Label: S0012_M_54_3_Cropped.jpg Actual Label: S0017_F_60_12_Cropped.jpg\n",
      "Data 16 Predicted Label: S0008_F_25_19_Cropped.jpg Actual Label: S0008_F_25_18_Cropped.jpg\n",
      "Data 17 Predicted Label: S0008_F_25_5_Cropped.jpg Actual Label: S0006_F_10_28_Cropped.jpg\n",
      "Data 18 Predicted Label: S0014_M_54_16_Cropped.jpg Actual Label: S0023_F_22_6_Cropped.jpg\n",
      "Data 19 Predicted Label: S0004_M_16_2_Cropped.jpg Actual Label: S0004_M_16_8_Cropped.jpg\n",
      "Data 20 Predicted Label: S0009_M_22_20_Cropped.jpg Actual Label: S0009_M_22_30_Cropped.jpg\n",
      "Data 21 Predicted Label: S0001_F_30_16_Cropped.jpg Actual Label: S0001_F_30_15_Cropped.jpg\n",
      "Data 22 Predicted Label: S0014_M_54_7_Cropped.jpg Actual Label: S0003_M_32_3_Cropped.jpg\n",
      "Data 23 Predicted Label: S0006_F_10_17_Cropped.jpg Actual Label: S0006_F_10_23_Cropped.jpg\n",
      "Data 24 Predicted Label: S0004_M_16_29_Cropped.jpg Actual Label: S0021_M_25_12_Cropped.jpg\n",
      "Data 25 Predicted Label: S0004_M_16_33_Cropped.jpg Actual Label: S0001_F_30_35_Cropped.jpg\n",
      "Data 26 Predicted Label: S0005_M_11_8_Cropped.jpg Actual Label: S0005_M_11_9_Cropped.jpg\n",
      "Data 27 Predicted Label: S0019_F_63_11_Cropped.jpg Actual Label: S0019_F_63_18_Cropped.jpg\n",
      "Data 28 Predicted Label: S0015_M_26_14_Cropped.jpg Actual Label: S0015_M_26_7_Cropped.jpg\n",
      "Data 29 Predicted Label: S0018_F_43_15_Cropped.jpg Actual Label: S0018_F_43_7_Cropped.jpg\n",
      "Data 30 Predicted Label: S0014_M_54_7_Cropped.jpg Actual Label: S0014_M_54_6_Cropped.jpg\n",
      "Data 31 Predicted Label: S0012_M_54_4_Cropped.jpg Actual Label: S0017_F_60_15_Cropped.jpg\n",
      "Data 32 Predicted Label: S0019_F_63_16_Cropped.jpg Actual Label: S0019_F_63_25_Cropped.jpg\n",
      "Data 33 Predicted Label: S0012_M_54_16_Cropped.jpg Actual Label: S0013_M_34_12_Cropped.jpg\n",
      "Data 34 Predicted Label: S0006_F_10_11_Cropped.jpg Actual Label: S0014_M_54_18_Cropped.jpg\n",
      "Data 35 Predicted Label: S0018_F_43_16_Cropped.jpg Actual Label: S0018_F_43_17_Cropped.jpg\n",
      "Data 36 Predicted Label: S0004_M_16_34_Cropped.jpg Actual Label: S0021_M_25_16_Cropped.jpg\n",
      "Data 37 Predicted Label: S0009_M_22_5_Cropped.jpg Actual Label: S0009_M_22_4_Cropped.jpg\n",
      "Data 38 Predicted Label: S0004_M_16_28_Cropped.jpg Actual Label: S0004_M_16_20_Cropped.jpg\n",
      "Data 39 Predicted Label: S0001_F_30_10_Cropped.jpg Actual Label: S0001_F_30_9_Cropped.jpg\n",
      "Data 40 Predicted Label: S0004_M_16_27_Cropped.jpg Actual Label: S0004_M_16_26_Cropped.jpg\n",
      "Data 41 Predicted Label: S0001_F_30_26_Cropped.jpg Actual Label: S0009_M_22_22_Cropped.jpg\n",
      "Data 42 Predicted Label: S0019_F_63_16_Cropped.jpg Actual Label: S0019_F_63_26_Cropped.jpg\n",
      "Data 43 Predicted Label: S0009_M_22_15_Cropped.jpg Actual Label: S0009_M_22_2_Cropped.jpg\n",
      "Data 44 Predicted Label: S0006_F_10_9_Cropped.jpg Actual Label: S0006_F_10_10_Cropped.jpg\n",
      "Data 45 Predicted Label: S0019_F_63_12_Cropped.jpg Actual Label: S0019_F_63_9_Cropped.jpg\n",
      "Data 46 Predicted Label: S0014_M_54_5_Cropped.jpg Actual Label: S0003_M_32_6_Cropped.jpg\n",
      "Data 47 Predicted Label: S0013_M_34_8_Cropped.jpg Actual Label: S0013_M_34_6_Cropped.jpg\n",
      "Data 48 Predicted Label: S0014_M_54_7_Cropped.jpg Actual Label: S0022_M_47_16_Cropped.jpg\n",
      "Data 49 Predicted Label: S0008_F_25_23_Cropped.jpg Actual Label: S0008_F_25_20_Cropped.jpg\n",
      "Data 50 Predicted Label: S0008_F_25_23_Cropped.jpg Actual Label: S0008_F_25_27_Cropped.jpg\n",
      "Data 51 Predicted Label: S0009_M_22_9_Cropped.jpg Actual Label: S0005_M_11_16_Cropped.jpg\n",
      "Data 52 Predicted Label: S0001_F_30_23_Cropped.jpg Actual Label: S0001_F_30_25_Cropped.jpg\n",
      "Data 53 Predicted Label: S0004_M_16_9_Cropped.jpg Actual Label: S0004_M_16_3_Cropped.jpg\n",
      "Data 54 Predicted Label: S0008_F_25_23_Cropped.jpg Actual Label: S0008_F_25_24_Cropped.jpg\n",
      "Data 55 Predicted Label: S0015_M_26_17_Cropped.jpg Actual Label: S0001_F_30_17_Cropped.jpg\n",
      "Data 56 Predicted Label: S0008_F_25_10_Cropped.jpg Actual Label: S0004_M_16_39_Cropped.jpg\n",
      "Data 57 Predicted Label: S0001_F_30_23_Cropped.jpg Actual Label: S0008_F_25_25_Cropped.jpg\n",
      "Data 58 Predicted Label: S0022_M_47_14_Cropped.jpg Actual Label: S0022_M_47_10_Cropped.jpg\n",
      "Data 59 Predicted Label: S0019_F_63_21_Cropped.jpg Actual Label: S0019_F_63_19_Cropped.jpg\n",
      "Data 60 Predicted Label: S0004_M_16_13_Cropped.jpg Actual Label: S0009_M_22_18_Cropped.jpg\n",
      "Data 61 Predicted Label: S0001_F_30_12_Cropped.jpg Actual Label: S0001_F_30_13_Cropped.jpg\n",
      "Data 62 Predicted Label: S0009_M_22_13_Cropped.jpg Actual Label: S0009_M_22_27_Cropped.jpg\n",
      "Data 63 Predicted Label: S0009_M_22_6_Cropped.jpg Actual Label: S0009_M_22_26_Cropped.jpg\n",
      "Data 64 Predicted Label: S0017_F_60_7_Cropped.jpg Actual Label: S0015_M_26_1_Cropped.jpg\n",
      "Data 65 Predicted Label: S0014_M_54_4_Cropped.jpg Actual Label: S0004_M_16_23_Cropped.jpg\n",
      "Data 66 Predicted Label: S0009_M_22_23_Cropped.jpg Actual Label: S0018_F_43_3_Cropped.jpg\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but KNeighborsClassifier is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Plotting the decision boundaries with only the first two features\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[43mplot_decision_boundaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "Cell \u001b[0;32mIn[18], line 61\u001b[0m, in \u001b[0;36mplot_decision_boundaries\u001b[0;34m(X, y, knn_clf)\u001b[0m\n\u001b[1;32m     58\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X_pca[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X_pca[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     59\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39marange(x_min, x_max, \u001b[38;5;241m0.02\u001b[39m), np\u001b[38;5;241m.\u001b[39marange(y_min, y_max, \u001b[38;5;241m0.02\u001b[39m))\n\u001b[0;32m---> 61\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mknn_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m Z \u001b[38;5;241m=\u001b[39m Z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Plot decision boundaries\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:274\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    277\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neighbors/_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 2 features, but KNeighborsClassifier is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# /Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/Face_Output/Face_Output_Split_Train/X_train.npy\n",
    "# /Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/Face_Output/Face_Output_Split_Train/y_train.npy\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "\n",
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Load training data\n",
    "    X_train = np.load(os.path.join(train_dir, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(train_dir, 'y_train.npy'))\n",
    "\n",
    "    # Loop through each training sample\n",
    "    for features, label in zip(X_train, y_train):\n",
    "        # Append features and corresponding label to X and y\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf\n",
    "\n",
    "\n",
    "def predict(X_test_path, knn_clf=None, model_path=None, distance_threshold=0.6):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        knn_model = pickle.load(f)\n",
    "    predictions = knn_model.predict(X_test_path)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # STEP 1: Train the KNN classifier and save it to disk\n",
    "    # Once the model is trained and saved, you can skip this step next time.\n",
    "    print(\"Training KNN classifier...\")\n",
    "    classifier = train(\"/Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/Face_Output/Face_Output_Split_Train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Load test data and model\n",
    "    data = np.load('/Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/Face_Output/Face_Output_Split_Test/X_test.npy')\n",
    "    actual_labels = np.load('/Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/Face_Output/Face_Output_Split_Test/y_test.npy')\n",
    "    model = \"/Users/zhengweing/Desktop/Current/CSCI158/FaceAndIris_Recognition/trained_knn_model.clf\"\n",
    "\n",
    "    # STEP 2: Using the trained classifier, make predictions for unknown images\n",
    "    predicted_labels = predict(X_test_path=data, model_path=model)\n",
    "\n",
    "    # Display each data's label and actual class\n",
    "    for i in range(len(actual_labels)):\n",
    "        print(\"Data\", i+1, \"Predicted Label:\", predicted_labels[i], \"Actual Label:\", actual_labels[i])\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct_predictions = np.sum(predicted_labels == actual_labels)\n",
    "    total_predictions = len(actual_labels)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
