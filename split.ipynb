{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_olivetti_faces, load_iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_validation_data(X, Y, fold_count, fold_test):\n",
    "    classes = np.unique(Y)\n",
    "    class_count = len(classes)\n",
    "\n",
    "    classes_element_ids = {}\n",
    "    block_size = np.zeros(class_count, dtype=int)  # Ensure block_size is of integer type\n",
    "\n",
    "    for class_id in range(class_count):\n",
    "        classes_element_ids[class_id] = np.where(Y == classes[class_id])[0]\n",
    "        \n",
    "        # Calculate block size for testing (20%) and training (80%)\n",
    "        block_size[class_id] = int(np.floor(len(classes_element_ids[class_id]) * 0.2)) if fold_test == 1 else int(np.floor(len(classes_element_ids[class_id]) * 0.8 / (fold_count - 1)))\n",
    "\n",
    "    element_test_ids = np.zeros(int(np.sum(block_size)), dtype=int)\n",
    "    element_train_ids = np.zeros(int(np.sum(block_size) * (fold_count - 1)), dtype=int)\n",
    "    element_validate_ids = np.zeros(int(np.sum(block_size)), dtype=int)\n",
    "\n",
    "    fold_validate = (fold_test % fold_count) + 1\n",
    "    stack_counter = 0\n",
    "\n",
    "    for class_id in range(class_count):\n",
    "        test_range = np.arange(1, block_size[class_id] + 1).astype(int) + (fold_test - 1) * block_size[class_id]\n",
    "        train_range = np.arange(1, block_size[class_id] * fold_count + 1).astype(int)\n",
    "        train_range = np.delete(train_range, (test_range - 1).astype(int))\n",
    "        validate_range = np.arange(1, block_size[class_id] + 1).astype(int) + (fold_validate - 1) * block_size[class_id]\n",
    "\n",
    "        element_test_ids[stack_counter:stack_counter + len(test_range)] = classes_element_ids[class_id][test_range - 1]\n",
    "        element_train_ids[stack_counter * (fold_count - 1):stack_counter * (fold_count - 1) + len(train_range)] = \\\n",
    "            classes_element_ids[class_id][train_range - 1]\n",
    "        element_validate_ids[stack_counter:stack_counter + len(validate_range)] = \\\n",
    "            classes_element_ids[class_id][validate_range - 1]\n",
    "\n",
    "        stack_counter += block_size[class_id]\n",
    "\n",
    "    test = {'X': X[element_test_ids, :], 'Y': Y[element_test_ids]}\n",
    "    train = {'X': X[element_train_ids, :], 'Y': Y[element_train_ids]}\n",
    "    validate = {'X': X[element_validate_ids, :], 'Y': Y[element_validate_ids]}\n",
    "\n",
    "    return test, train, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATASETS & SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face dataset\n",
    "faces = fetch_olivetti_faces(data_home='Dataset/VISA_Face/VISA_Face')\n",
    "X_faces = faces.data\n",
    "y_faces = faces.target\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Set fold count and fold test\n",
    "fold_count = 5\n",
    "fold_test = 1  # Testing on the first fold\n",
    "\n",
    "# Call the function to split the data\n",
    "test_faces, train_faces, validate_faces = get_cross_validation_data(X_faces, y_faces, fold_count, fold_test)\n",
    "test_iris, train_iris, validate_iris = get_cross_validation_data(X_iris, y_iris, fold_count, fold_test)\n",
    "\n",
    "# Print the results, testing purposes\n",
    "print(\"Face DATASET:\")\n",
    "print(\"\\nTest data:\", test_faces)\n",
    "print(\"\\nTrain data:\", train_faces)\n",
    "print(\"\\nValidation data:\", validate_faces)\n",
    "\n",
    "print(\"\\nIris DATASET:\")\n",
    "print(\"\\nTest data:\", test_iris)\n",
    "print(\"\\nTrain data:\", train_iris)\n",
    "print(\"\\nValidation data:\", validate_iris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
