{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re \n",
    "import warnings\n",
    "import tensorflow\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSE FACE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'Dataset/VISA_Face/VISA_Face'\n",
    "face_images = []\n",
    "def parse_face_dataset():\n",
    "    for path in glob.iglob(base_directory+'/*'):\n",
    "        filename = os.path.basename(path)\n",
    "        \n",
    "        #string manipulation\n",
    "        underscore_index = filename.find(\"_\")\n",
    "        filename_parsed = filename[:underscore_index]    \n",
    "        match = re.search(r\"(.*?)_2017_001\", filename)\n",
    "        filename_parsed = match.group(1)\n",
    "        \n",
    "        label = filename_parsed\n",
    "        # print('label: ' + label)\n",
    "        # print('path: ' + path )\n",
    "        image_id = 0\n",
    "        \n",
    "        for image_path in glob.iglob(path + '/*'):\n",
    "            # print('image path: ' + image_path)\n",
    "\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (400, 300))\n",
    "            face_images.append([image, image_id, label])\n",
    "            image_id += 1\n",
    "            \n",
    "    print('face images: ' + str(len(face_images)))    \n",
    "    return face_images   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(face_images):\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "    # Draw rectangle around the faces and crop the faces\n",
    "    for face_image in face_images:\n",
    "        (image, image_id, label) = face_image\n",
    "        image_id += 1\n",
    "        faces = face_cascade.detectMultiScale(image, 1.1, 0) \n",
    "        \n",
    "        (x, y, width, height) = image\n",
    "        cv2.rectangle(image, (x, y), (x+width, y+height), (0, 0, 255), 2)\n",
    "        face = image[y:y + height, x:x + width]\n",
    "        cv2.imshow(\"face\", face)\n",
    "        cv2.imwrite(\n",
    "            'Processed/'+str(label)+'.' + str(image_id)+'.bmp',\n",
    "            face\n",
    "        )\n",
    "\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imwrite('detcted.jpg', image)\n",
    "    cv2.imshow('img', image)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face images: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n",
      "[ERROR:0@876.873] global persistence.cpp:519 open Can't open file: 'haarcascade_frontalface_alt2.xml' in read mode\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m face_images \u001b[38;5;241m=\u001b[39m parse_face_dataset()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mface_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_images\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mface_detection\u001b[0;34m(face_images)\u001b[0m\n\u001b[1;32m      6\u001b[0m (image, image_id, label) \u001b[38;5;241m=\u001b[39m face_image\n\u001b[1;32m      7\u001b[0m image_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 8\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     10\u001b[0m (x, y, width, height) \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (x, y), (x\u001b[38;5;241m+\u001b[39mwidth, y\u001b[38;5;241m+\u001b[39mheight), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "face_images = parse_face_dataset()\n",
    "face_detection(face_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
