{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 15:12:12.438644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re \n",
    "import warnings\n",
    "import tensorflow\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSE FACE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'Dataset/VISA_Face/VISA_Face'\n",
    "face_images = []\n",
    "def parse_face_dataset():\n",
    "    for path in glob.iglob(base_directory+'/*'):\n",
    "        filename = os.path.basename(path)\n",
    "        \n",
    "        #string manipulation\n",
    "        underscore_index = filename.find(\"_\")\n",
    "        filename_parsed = filename[:underscore_index]    \n",
    "        match = re.search(r\"(.*?)_2017_001\", filename)\n",
    "        filename_parsed = match.group(1)\n",
    "        \n",
    "        label = filename_parsed\n",
    "        # print('label: ' + label)\n",
    "        # print('path: ' + path )\n",
    "        image_id = 0\n",
    "        \n",
    "        for image_path in glob.iglob(path + '/*'):\n",
    "            # print('image path: ' + image_path)\n",
    "\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (400, 300))\n",
    "            face_images.append([image, image_id, label])\n",
    "            image_id += 1\n",
    "            \n",
    "    print('face images: ' + str(len(face_images)))   \n",
    "    return face_images   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(face_images, display):\n",
    "    \n",
    "    pre_processed_images = []\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "    # Draw rectangle around the faces and crop the faces\n",
    "    for face_image in face_images:\n",
    "        (image, image_id, label) = face_image\n",
    "        image_id += 1\n",
    "        face = face_cascade.detectMultiScale(image, 1.1, 4)\n",
    "\n",
    "        for (x, y, width, height) in face:\n",
    "            face = image[y:y + height, x:x + width]\n",
    "            cv2.imshow(\"face\", face)\n",
    "            cv2.imwrite(\n",
    "                'Processed/'+str(label) + '.' +\n",
    "                str(image_id) + '.Face' + '.jpg',\n",
    "                face\n",
    "            )\n",
    "            pre_processed_images.append([face, image_id, label])\n",
    "\n",
    "            image_unboxed = image.copy()\n",
    "\n",
    "            image_cropped = image_unboxed[y:y + height,\n",
    "                                            x:x + width,]\n",
    "\n",
    "            image_boxed = cv2.rectangle(\n",
    "                image,\n",
    "                (x, y),\n",
    "                (x + width, y + height),\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "            )\n",
    "    \n",
    "    print(\"face image preprocessing done\")\n",
    "    if (display):\n",
    "        fig, axes = plot.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "        axes[0].imshow(image_unboxed)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')  # Hide axes for cleaner presentation\n",
    "\n",
    "        axes[1].imshow(image_boxed)\n",
    "        axes[1].set_title('Haar Face Cascade Classifier Detection')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        axes[2].imshow(image_cropped)\n",
    "        axes[2].set_title('Cropped Face')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        plot.tight_layout()\n",
    "        plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face images: 558\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'y' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m face_images \u001b[38;5;241m=\u001b[39m parse_face_dataset()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mface_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36mface_detection\u001b[0;34m(face_images, display)\u001b[0m\n\u001b[1;32m     20\u001b[0m         pre_processed_images\u001b[38;5;241m.\u001b[39mappend([face, image_id, label])\n\u001b[1;32m     22\u001b[0m     image_unboxed \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 24\u001b[0m     image_cropped \u001b[38;5;241m=\u001b[39m image_unboxed[\u001b[43my\u001b[49m:y \u001b[38;5;241m+\u001b[39m height,\n\u001b[1;32m     25\u001b[0m                                   x:x \u001b[38;5;241m+\u001b[39m width,]\n\u001b[1;32m     27\u001b[0m     image_boxed \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(\n\u001b[1;32m     28\u001b[0m         image,\n\u001b[1;32m     29\u001b[0m         (x, y),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface image preprocessing done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'y' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "face_images = parse_face_dataset()\n",
    "face_detection(face_images, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
