{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import face_utilities as face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHASE 1 - Parse the face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Face Dataset STARTED...\n",
      "Total Face Images Found: 558\n",
      "Length: 558 | 558\n",
      "Parsing Face Dataset COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "print('Parsing Face Dataset STARTED...')\n",
    "images, labels = face.parse_face_dataset()\n",
    "print('Length:', len(images), '|', len(labels))\n",
    "print('Parsing Face Dataset COMPLETE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHASE 2 - Perform face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Image Preprocessing STARTED...\n",
      "Length: 490 | 490\n",
      "Face Image Preprocessing COMPLETE!\n",
      "Saving...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Face Image Preprocessing STARTED...')\n",
    "cropped_images, cropped_labels = face.detect_faces(zip(images, labels))\n",
    "print('Length:', len(cropped_images), '|', len(cropped_labels))\n",
    "print('Face Image Preprocessing COMPLETE!')\n",
    "\n",
    "print('Saving...')\n",
    "pickle.dump(cropped_images, open(os.path.join('Face_Output', 'cropped_faces.pickle'), 'wb'))\n",
    "numpy.save(os.path.join('Face_Output', 'cropped_labels'), cropped_labels)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHASE 3 - Perform facial feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Feature Extraction STARTED...\n",
      "Length: 334 | 334\n",
      "Face Feature Extraction COMPLETE!\n",
      "Saving feature array...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Face Feature Extraction STARTED...\")\n",
    "features, feature_labels = face.extract_features(zip(cropped_images, labels))\n",
    "print('Length:', len(features), '|', len(feature_labels))\n",
    "print(\"Face Feature Extraction COMPLETE!\")\n",
    "\n",
    "print('Saving feature array...')\n",
    "numpy.save(os.path.join('Face_Output', 'features'), features)\n",
    "numpy.save(os.path.join('Face_Output', 'feature_labels'), feature_labels)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Obsolete) PHASE 4 - Extract facial landmarks from an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting facial landmarks STARTED...\")\n",
    "# Input directory containing images with extracted facial features\n",
    "input_directory_extraction = 'Face_Output/Face_Output_Feature_Extraction'\n",
    "# Output directory for saving images with facial landmarks\n",
    "output_directory_landmarks = 'Face_Output'\n",
    "face.extract_facial_landmarks(\n",
    "    input_directory_extraction, output_directory_landmarks)\n",
    "print(\"Extracting facial landmarks COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Obsolete) PHASE 5 - Convert facial landmarks into feature vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting facial landmarks to feature vectors STARTED...\")\n",
    "\n",
    "# Assuming you have extracted landmarks and stored them in 'features'\n",
    "# and you want to save the feature vectors in 'output_dir'\n",
    "output_dir = 'Face_Output/Face_Output_LFCV'\n",
    "face.landmarks_to_features(features, output_dir=output_dir)\n",
    "\n",
    "print(\"Converting facial landmarks to feature vectors COMPLETE!\")\n",
    "\n",
    "# View the stored feature vectors\n",
    "stored_feature_vectors = []\n",
    "\n",
    "# Iterate over files in the output directory\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('.npy'):  # Check if the file is a NumPy binary file\n",
    "        # Construct the file path\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        # Load the data from the file\n",
    "        feature_vector = face.np.load(filepath)\n",
    "        # Append the feature vector to the list\n",
    "        stored_feature_vectors.append(feature_vector)\n",
    "        # Print the contents of the feature vector\n",
    "        print(\"Feature vector from file:\", filename)\n",
    "        print(feature_vector)\n",
    "\n",
    "# Print the number of stored feature vectors\n",
    "print(\"Number of feature vectors generated:\", len(stored_feature_vectors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
